# MAKE APP DATA FROM RESULTS_PARQUET.ZIP

librarian::shelf(
  arrow, dplyr,
  sf, sfarrow,
  giscoR
)

# 1. download results_parquet from https://zenodo.org/records/14004322
#   note download path


# 2. prepare geom data
#   (accesses V://)

# city points
unzip("V:/VolumeQ/AGteam/Eurostat/geography/URAU/URAU_PT_2020_4326.shp.zip")
geom_city <- st_read("URAU_PT_2020_4326.shp")
file.remove(grep("URAU_PT_2020_4326",dir(), value=T))

geom_city <- geom_city %>% filter(URAU_CATG!="FUA") %>%
  select(-POP_2020, -AREA_KM2, -URAU_CATG)
geom_city[geom_city$URAU_CODE=="EL001C","URAU_NAME"] <- "Athina"
geom_city[,c("x","y")] <- st_coordinates(geom_city)
geom_city$URAU_CODE <- as.factor(geom_city$URAU_CODE)

# country geoms
unzip("V:/VolumeQ/AGteam/Eurostat/geography/NUTS/NUTS_RG_20M_2021_4326.shp.zip")
geom_country <- st_read("NUTS_RG_20M_2021_4326.shp")
file.remove(grep("NUTS_RG_20M_2021_4326",dir(), value=T))

geom_country <- geom_country %>%
  filter(LEVL_CODE==0) %>%
  select(-LEVL_CODE, -NUTS_ID,-NUTS_NAME,-MOUNT_TYPE, -URBN_TYPE, -COAST_TYPE, -FID)

# geom regions
geom_region <- st_read("data-raw/EU_RGN/eu_region.shp")

# lookup labels (city dataset has ? characters)
disp_names <- read.csv("V:/VolumeQ/AGteam/Eurostat/lookup/URAU_NUTS_2021.csv") %>%
  select(city_code=URAU_CODE, city_name=CITY.NAME, country_code=CNTR_CODE) %>%
  distinct(.)
disp_names[disp_names$city_code=="EL001C","city_name"] <- "Athina"

# add some english names
engnames <- read.csv("V:/VolumeQ/AGteam/Eurostat/lookup/URAU_DisplayNames.csv") %>%
  select(city_code=URAU_CODE, city_name=LABEL) %>% filter(!grepl("F$",city_code)) %>%
  mutate(country_code=substr(city_code,1,2))
disp_names[disp_names$city_code%in%engnames$city_code,] <- engnames

cntr_names <-  gisco_countries %>%
  dplyr::select(country_code=CNTR_ID, country_name=NAME_ENGL) %>%
  st_drop_geometry(.);

lookup <- left_join(disp_names,cntr_names)
lookup[lookup$city_code=="ES069C","city_name"] <- "CastellÃ³n de la Plana"
rm(disp_names,cntr_names)

# 3. define function for joining parquet to geoms and pre-process

# factor columns
fac_cols <- c("period", "level","city","country","region",
              "ssp", "range", "ssp", "adapt","sc", "agegroup",
              "city_code","city_name","country_code","country_name")

# FX FROM PARQUET FILE TO APP-DATA WITH CITY, COUNTRIES, REGION GEOMS
prep_app_data <- function(readparquet, geom, lk=lookup, fct_cols=fac_cols) {

  if (geom=="city") {
    d <- left_join(readparquet, select(geom_city,-CC,-URAU_NAME),
                    by=c("city"="URAU_CODE")) %>%
      left_join(.,lk, by = c("city"="city_code")) %>%
      st_as_sf(., coords=c("x","y"), crs=4326)

  } else if  (geom=="ctry") {
    d <- left_join(readparquet, select(geom_country,-NAME_LATN),
                    by=c("country"="CNTR_CODE")) %>%
      left_join(., distinct(select(lk,country_name,country_code)),
                by = c("country"="country_code")) %>%
      st_as_sf(.,sf_column_name="geometry", crs=4326)

  } else if (geom=="rg") {
    d <- left_join(readparquet, geom_region, by=c("region"="region")) %>%
      st_as_sf(.,sf_column_name="geometry", crs=4326)
  }

  # FACTORS
  out <- d %>% mutate(across(
    any_of(fct_cols), as.factor
  )) %>%
  # ATTRIBUTABLE FRAC AND RATE TO BETTER VALUES
    mutate(across(contains("af"),~.x*100),
           across(contains("rate"),~.x*100000))

  return(out)
}

# 4. unzip and process files
#   unzip creates dir in working directory
unzip("C:/Users/lshad21/Downloads/results_parquet.zip", junkpaths = F)

pqfs <- setNames(
  as.list(grep(paste0(c("city","country","region"),
              collapse = "|"),
       dir("results_parquet/", full.names = T), value=T)),
  c("city_level", "city_period",
    "country_level", "country_period",
    "region_level","region_period"))

# WARNINGS EXPECTED (EXACT REASON UNKNOWN)
options(arrow.unsafe_metadata = F)
# c(2010,2015,2020, 2025, 2030, 2035, 2040, 2045, 2050, 2055, 2060, 2065, 2070, 2075, 2080, 2085, 2090 2095)
city_level <- read_parquet(pqfs$city_level)
city_period<- read_parquet(pqfs$city_period) %>% filter(period %in% c(2010,2020,2030,2040,2050,2060,2070,2080,2090))
country_level <- read_parquet(pqfs$country_level)
country_period <- read_parquet(pqfs$country_period) %>% filter(period %in% c(2010,2020,2030,2040,2050,2060,2070,2080,2090))
region_level <- read_parquet(pqfs$region_level)
region_period <- read_parquet(pqfs$region_period) %>% filter(period %in% c(2010,2020,2030,2040,2050,2060,2070,2080,2090))

# somehow i can only manage to delete the files, leaving an empty dir
unlink(x=paste0(getwd(),"/results_parquet"), recursive=TRUE)
file.remove(dir("results_parquet", full.names = T))

# PROCESS
ci_le <- prep_app_data(city_level, "city")
ci_pe <- prep_app_data(city_period, "city")
co_le <- prep_app_data(country_level, "ctry")
co_pe <- prep_app_data(country_period, "ctry")
re_le <- prep_app_data(region_level, "rg")
re_pe <- prep_app_data(region_period, "rg")

## MAKE OPTIONS VECTORS - no need to rerun - sysdata.RDS loads all and is in git
# Celsisus degree and exponent 6 ascii vs non-ascii characters
level_ov <- levels(ci_le$level); names(level_ov) <- paste0(level_ov, "&#176;C")
period_ov <- levels(co_pe$period);
adapt_ov <- levels(ci_le$adapt)
range_ov <- levels(co_pe$range); names(range_ov) <- c("Cold","Heat","Total")
ssp_ov <- levels(co_pe$ssp); names(ssp_ov) <- paste0("SSP",ssp_ov,"-",c("2.6","4.5","7.0"))
sc_ov <- levels(ci_le$sc); names(sc_ov) <- c("Climate change", "Demographic change", "Both")
agegroup_ov <- levels(co_pe$agegroup); names(agegroup_ov) <- agegroup_ov; names(agegroup_ov)[6] <- "All"
city_ov <- levels(ci_pe$city);
country_ov <- levels(co_pe$country)
region_ov <- levels(re_pe$region)
outcomes_ov <- gsub("_est","",grep("est", names(re_le), value = T)); names(outcomes_ov) <-
  c("Excess deaths","Attributable fraction (%)", "Excess death rate (x10\u2075)","Cumulative excess deaths")

# works with spaces
ordered_newnames <- c(
  "Level" = "level", "Period" = "period", "Adaptation" = "adapt", "Temp range" = "range",
  "SSP" = "ssp", "Sc" = "sc", "Age group" = "agegroup", "Country code" = "country_code",
  "Country" = "country_name", "City" = "city_name", "City code" = "city", "Region" = "region",
  "Excess deaths" = "an_est", "AF(%)" = "af_est", "Rate(x10\u2075)" = "rate_est", "Cumulative" = "cuman_est",
  setNames(
    paste0(rep(c("an", "af", "rate", "cuman"), each = 2), c("_low", "_high")),
    paste0(rep(c("Exc.deaths", "AF", "Rate", "Cumulative"), each = 2), c("_low", "_high"))
  )
)

usethis::use_data(adapt_ov,agegroup_ov,city_ov, country_ov, level_ov, outcomes_ov,
                  period_ov, range_ov, region_ov, ssp_ov, sc_ov, ordered_newnames,
                  internal=TRUE, overwrite = TRUE)

## SAVE PARITTIONED PARQUET FILES - warning expected
sfarrow::write_sf_dataset(ci_le,"inst/extdata/city_level",format="parquet", partitioning="agegroup")
sfarrow::write_sf_dataset(ci_pe,"inst/extdata/city_period",format="parquet", partitioning="agegroup")
sfarrow::write_sf_dataset(co_le,"inst/extdata/country_level",format="parquet", partitioning="agegroup")
sfarrow::write_sf_dataset(co_pe,"inst/extdata/country_period",format="parquet", partitioning="agegroup")
sfarrow::write_sf_dataset(re_le,"inst/extdata/region_level", format = "parquet", partitioning="agegroup")
sfarrow::write_sf_dataset(re_pe,"inst/extdata/region_period", format = "parquet", partitioning="agegroup")


# # CHECK ASCII CHARCTERS IN  OPTION VECTORS
# check_ascii <- function(x) {
#   result <- list()
#
#   # Check values for non-ASCII characters
#   if (is.character(x)) {
#     cleaned <- iconv(x, from = "UTF-8", to = "ASCII//TRANSLIT", sub = "byte")
#     result$values <- x[!is.na(cleaned) & cleaned != x]
#   }
#
#   # Check names for non-ASCII characters
#   if (!is.null(names(x))) {
#     cleaned_names <- iconv(names(x), from = "UTF-8", to = "ASCII//TRANSLIT", sub = "byte")
#     result$names <- names(x)[!is.na(cleaned_names) & cleaned_names != names(x)]
#   }
#
#   # Check lists recursively
#   if (is.list(x)) {
#     result$list <- lapply(x, check_ascii)
#   }
#
#   # Filter out empty results
#   result <- Filter(function(y) length(y) > 0, result)
#
#   if (length(result) == 0) return(NULL)
#   return(result)
# }
#
#
# load("R/sysdata.rda")
#
# # Apply to all objects
# results <- lapply(ls(), function(var) check_ascii(get(var)))
# results
